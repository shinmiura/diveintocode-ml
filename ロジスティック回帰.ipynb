{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ロジスティック回帰.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZUj1hnoMZ36CHGNf_w6r7wzUByu-yh6w",
      "authorship_tag": "ABX9TyPJ8rgdjxnJshPVbmKY6Wfx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinmiura/diveintocode-ml/blob/master/%E3%83%AD%E3%82%B8%E3%82%B9%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E5%9B%9E%E5%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBomJ0T0ZB0D"
      },
      "source": [
        "**Sprintの目的**\n",
        "\n",
        "・スクラッチを通してロジスティック回帰を理解する\n",
        "\n",
        "・分類問題についての基礎を学ぶ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EedTMq-ZQBF"
      },
      "source": [
        "**どのように学ぶか**\n",
        "\n",
        "スクラッチでロジスティック回帰を実装した後、学習と検証を行なっていきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mobaTix4O4iq"
      },
      "source": [
        "【ロジスティック回帰の前提】\n",
        "\n",
        "1. 説明変数(x)は連続値 or 離散値で、目的変数(y)は離散値である。\n",
        "2. 予測値()は、ベルヌーイ分布 / 二項分布(平均np、分散np(1-p))に従う。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTCL__10ZbJH"
      },
      "source": [
        "# 2.ロジスティック回帰スクラッチ\n",
        "\n",
        "ロジスティック回帰のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
        "\n",
        "\n",
        "以下に雛形を用意してあります。このScratchLogisticRegressionクラスにコードを書き加えていってください。推定関係のメソッドは線形回帰と異なり、ラベルを出力するpredictメソッドと、確率を出力するpredict_probaメソッドの2種類を作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHYFYyjqPb4a"
      },
      "source": [
        "# 必要なライブラリの読み込み\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ1A06SVZPvJ"
      },
      "source": [
        "# 雛形\n",
        "\n",
        "class ScratchLogisticRegression():\n",
        "    \"\"\"\n",
        "    ロジスティック回帰のスクラッチ実装\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_iter : int\n",
        "      イテレーション数\n",
        "    lr : float\n",
        "      学習率\n",
        "    no_bias : bool\n",
        "      バイアス項を入れない場合はTrue\n",
        "    verbose : bool\n",
        "      学習過程を出力する場合はTrue\n",
        "    Attributes\n",
        "    ----------\n",
        "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
        "      パラメータ\n",
        "    self.loss : 次の形のndarray, shape (self.iter,)\n",
        "      訓練データに対する損失の記録\n",
        "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
        "      検証データに対する損失の記録\n",
        "    \"\"\"\n",
        "    def __init__(self, num_iter, lr, bias, verbose, lamb = 0.1):\n",
        "        # ハイパーパラメータを属性として記録\n",
        "        self.iter = num_iter\n",
        "        self.lr = lr\n",
        "        self.bias = bias\n",
        "        self.verbose = verbose\n",
        "        self.lamb = lamb\n",
        "        # 損失を記録する配列を用意\n",
        "        self.loss = np.zeros(self.iter + 1)\n",
        "        self.val_loss = np.zeros(self.iter + 1)\n",
        "        # θの初期化\n",
        "        self.theta = np.random.rand(X.shape[1]+1)\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        \"\"\"\n",
        "        ロジスティック回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            訓練データの特徴量\n",
        "        y : 次の形のndarray, shape (n_samples, )\n",
        "            訓練データの正解値\n",
        "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
        "            検証データの特徴量\n",
        "        y_val : 次の形のndarray, shape (n_samples, )\n",
        "            検証データの正解値\n",
        "        \"\"\"\n",
        "        # 損失の初期化\n",
        "        self.loss[0] = self.mean_crossentropy_error(X, y)\n",
        "        if X_val is not None:\n",
        "          self.val_loss[0] = self.mean_crossentropy_error(X_val, y_val)\n",
        "        \n",
        "        #　反復して損失を取得\n",
        "        for i in range(self.iter):\n",
        "          self.loss[i + 1] = self.gradient_descent(X, y)\n",
        "          if X_val is not None:\n",
        "            self.val_loss[i + 1] = self.mean_crossentropy_error(X_val, y_val)\n",
        "        print(self.predict_proba(X))\n",
        "\n",
        "        if self.verbose:\n",
        "            #verboseをTrueにした際は学習過程を出力\n",
        "            print()\n",
        "        pass\n",
        "    \n",
        "    # 問題2\n",
        "    def gradient_descent(self, X, y):\n",
        "        \"\"\"\n",
        "        最急降下法によるパラメータの更新値計算\n",
        "        \"\"\"\n",
        "        error = (self.predict_proba(X) - y.flatten()) # n次元のNumpy配列yを1次元のNumpy配列に変換\n",
        "        grad = np.dot(X.T, error) / X.shape[0]\n",
        "        bias_grad = np.sum(error) / X.shape[0]\n",
        "        l2 = self.lamb * self.theta[:-1] / X.shape[0]\n",
        "        self.theta[:-1] = self.theta[:-1] -self.lr * (grad + l2)\n",
        "        self.theta[-1] = self.theta[-1] -self.lr * bias_grad\n",
        "        loss = self.mean_crossentropy_error(X, y)\n",
        "        return loss\n",
        "\n",
        "    # 問題3\n",
        "    # 推定する仕組みを実装する\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        ロジスティック回帰を使いラベルを推定する。\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            サンプル\n",
        "        Returns\n",
        "        -------\n",
        "            次の形のndarray, shape (n_samples, 1)\n",
        "            ロジスティック回帰による推定結果\n",
        "        \"\"\"\n",
        "        # クラスを決定するために、予測確率の値を確認し、比較する。0.5以上なら1を、未満なら0を返す。\n",
        "        return np.where(self.predict_proba(X) >= 0.5, 1, 0)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        ロジスティック回帰を使い確率を推定する。\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (n_samples, n_features)\n",
        "            サンプル\n",
        "        Returns\n",
        "        -------\n",
        "            次の形のndarray, shape (n_samples, 1)\n",
        "            ロジスティック回帰による推定結果\n",
        "        \"\"\"\n",
        "        # 線形回帰の仮定関数の実装\n",
        "        a = np.dot(self.theta[:-1], X.T) + self.theta[-1]\n",
        "        # シグモイド関数を通す \n",
        "        y = self.sigmoid(a)\n",
        "        return y\n",
        "    \n",
        "    # シグモイド関数を通す\n",
        "    def sigmoid(self, a):\n",
        "      return 1 / (1 + np.exp(-a))\n",
        "    \n",
        "    # 問題4\n",
        "    # ロジスティック回帰の目的関数(損失関数)を実装\n",
        "    def mean_crossentropy_error(self, X, t):\n",
        "        \"\"\"\n",
        "        損失関数\n",
        "        \"\"\"\n",
        "        # クロスエントロピー誤差の定義、Weight decay(過学習抑制のためにの手法)、L2正則化\n",
        "        y = self.predict_proba(X)\n",
        "        crossentropy = -np.sum(t * np.log(y) + (1 - t) * np.log(1 - y)) / X.shape[0]\n",
        "        l2_decay = np.sum(self.theta[:-1] ** 2) / (2 * X.shape[0])\n",
        "        return crossentropy + l2_decay"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7SvCoR2eKM_"
      },
      "source": [
        "【問題1】仮定関数\n",
        "\n",
        "ロジスティック回帰の仮定関数のメソッドをScratchLogisticRegressionクラスに実装してください。\n",
        "\n",
        "\n",
        "ロジスティック回帰の仮定関数は、線形回帰の仮定関数を シグモイド関数 に通したものです。シグモイド関数は以下の式で表されます。\n",
        "\n",
        "$$\n",
        "g(z) = \\frac{1}{1+e^{−z}}\n",
        "$$\n",
        "\n",
        "線形回帰の仮定関数は次の式でした。\n",
        "$$\n",
        "h_\\theta(x) = \\theta^T \\cdot x.\n",
        "$$\n",
        "\n",
        "まとめて書くと、ロジスティック回帰の仮定関数は次のようになります。\n",
        "$$\n",
        "h_\\theta(x) = \\frac{1}{1+e^{−\\theta^T \\cdot x}}\n",
        "$$\n",
        "\n",
        "$x$ : 特徴量ベクトル\n",
        "\n",
        "$\\theta$ : パラメータ（重み）ベクトル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVi83q1Rntqb"
      },
      "source": [
        "【問題2】最急降下法\n",
        "\n",
        "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fitメソッドから呼び出すようにしてください。\n",
        "\n",
        "$$\n",
        "\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_0} = \\frac{1}{m}  \\sum_{i=1}^{m}(h_θ(x^{(i)}) − y^{(i)})x_j^{(i)}  ,j = 0\\\\ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\biggl(\\frac{1}{m}  \\sum_{i=1}^{m}(h_θ(x^{(i)}) − y^{(i)})x_j^{(i)} \\biggr) + \\frac{λ}{m}\\theta_j　 ,j\\geq 1\n",
        "$$\n",
        "\n",
        "$\\alpha$ : 学習率\n",
        "\n",
        "\n",
        "$i$ : サンプルのインデックス\n",
        "\n",
        "\n",
        "$j$ : 特徴量のインデックス\n",
        "\n",
        "\n",
        "$m$ : 入力されるデータの数\n",
        "\n",
        "\n",
        "$h_\\theta()$ : 仮定関数\n",
        "\n",
        "\n",
        "$x$ : 特徴量ベクトル\n",
        "\n",
        "\n",
        "$\\theta$ : パラメータ（重み）ベクトル\n",
        "\n",
        "\n",
        "$x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
        "\n",
        "\n",
        "$y^{(i)}$ : i番目のサンプルの正解ラベル\n",
        "\n",
        "\n",
        "$\\theta_j$ : j番目のパラメータ（重み）\n",
        "\n",
        "\n",
        "$λ$ : 正則化パラメータ\n",
        "\n",
        "以上の式には正則化項が含まれます。正則化項は過学習を防ぐ目的で用いられます。切片である$\\theta_0$が正則化項に含まれていないのは、切片を除いた、特徴量に対する係数を同じ視点で議論することができるようにするためです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noPnB5xRoqGG"
      },
      "source": [
        "【問題3】推定\n",
        "\n",
        "推定する仕組みを実装してください。ScratchLogisticRegressionクラスの雛形に含まれるpredictメソッドとpredict_probaメソッドに書き加えてください。\n",
        "\n",
        "\n",
        "仮定関数 $h_\\theta(x)$ の出力がpredict_probaの戻り値、さらにその値に閾値を設けて1と0のラベルとしたものがpredictの戻り値となります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmVQVZ_PpWQa"
      },
      "source": [
        "【問題4】目的関数\n",
        "\n",
        "以下の数式で表されるロジスティック回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。\n",
        "\n",
        "\n",
        "なお、この数式には正則化項が含まれています。\n",
        "\n",
        "\n",
        "＊数式が見切れる場合、DIVERを全画面にして御覧ください。\n",
        "\n",
        "$$\n",
        "J(\\theta)=  \\frac{1}{m}  \\sum_{i=1}^{m}[−y^{(i)} log(h_θ(x^{(i)})) − (1−y^{(i)}) log(1−h_θ(x^{(i)}))] +\n",
        "\\frac{λ}{2m}\\sum_{j=1}^n\n",
        "θ^2_j\\\\\n",
        "$$\n",
        "\n",
        "$m$ : 入力されるデータの数\n",
        "\n",
        "\n",
        "$h_\\theta()$ : 仮定関数\n",
        "\n",
        "\n",
        "$x$ : 特徴量ベクトル\n",
        "\n",
        "\n",
        "$\\theta$ : パラメータ（重み）ベクトル\n",
        "\n",
        "\n",
        "$x^{(i)}$ : i番目のサンプルの特徴量ベクトル\n",
        "\n",
        "\n",
        "$y^{(i)}$ : i番目のサンプルの正解ラベル\n",
        "\n",
        "\n",
        "$\\theta_j$ : j番目のパラメータ（重み）\n",
        "\n",
        "\n",
        "$n$ : 特徴量の数\n",
        "\n",
        "\n",
        "$λ$ : 正則化パラメータ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bKIhgQDyoWL"
      },
      "source": [
        "# 3.検証"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osaMfeM5ysbe"
      },
      "source": [
        "【問題5】学習と推定\n",
        "\n",
        "機械学習スクラッチ入門のSprintで用意したirisデータセットのvirgicolorとvirginicaの2値分類に対してスクラッチ実装の学習と推定を行なってください。\n",
        "\n",
        "\n",
        "scikit-learnによる実装と比べ、正しく動いているかを確認してください。\n",
        "\n",
        "\n",
        "AccuracyやPrecision、Recallなどの指標値はscikit-learnを使用してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj2avOKrg9FX"
      },
      "source": [
        "# ヒント集に書いてあった実装の手順\n",
        "# 最急降下法の流れに則ると、下記の流れで実装していくとよいでしょう。\n",
        "# 1. 学習率や学習回数の初期化＆シータの初期化（`no_bias`や`verbose`については、アドバンス課題のため考慮しなくてもよい）\n",
        "# 2. 推定値算出\n",
        "# 3. 値更新\n",
        "# 4. 2,3を学習回数文繰り返す"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peD-FeqRP8Zg"
      },
      "source": [
        "# irisデータセット読み込み\n",
        "from sklearn.datasets import load_iris\n",
        "iris_dataset = load_iris()"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WIjp-9cQst6",
        "outputId": "f44cb15f-ed47-4677-d8e4-997f792087bb"
      },
      "source": [
        "print(iris_dataset)\n",
        "print(len(iris_dataset))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.6, 1.4, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/iris.csv'}\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62w32SAy4ZH7"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = iris_dataset.data[50:, :]\n",
        "y = iris_dataset.target[50:]\n",
        "y = np.where(y == 1, 0, 1)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "y = y.reshape([100, 1])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYIPS4CMRL00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1049d1e3-938a-4bfa-c09b-661539ec9ab6"
      },
      "source": [
        "# pandasデータに格納\n",
        "iris_df = pd.DataFrame(X, columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']) \n",
        "# ターゲット変数の抽出およびカラム名の指定\n",
        "iris_label = pd.DataFrame(y, columns = [\"Species\"])\n",
        "iris_df.head()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.4</td>\n",
              "      <td>3.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.5</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width\n",
              "0           7.0          3.2           4.7          1.4\n",
              "1           6.4          3.2           4.5          1.5\n",
              "2           6.9          3.1           4.9          1.5\n",
              "3           5.5          2.3           4.0          1.3\n",
              "4           6.5          2.8           4.6          1.5"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYgBktyrmGDj"
      },
      "source": [
        "# trainデータとtestデータへの分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGvxQq0xQw-y",
        "outputId": "1c7c0026-36ad-4410-d9bf-2fda35592538"
      },
      "source": [
        "# ロジスティック回帰のスクラッチ実装をここで呼び出す\n",
        "slr = ScratchLogisticRegression(num_iter=10000, lr=0.0001, bias=True, verbose=True)\n",
        "slr.fit(X_train,y_train.reshape(-1,1),X_test,y_test.reshape(-1,1))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.4401868  0.54846854 0.42917444 0.50779725 0.40517258 0.38368202\n",
            " 0.45494755 0.4749527  0.50030383 0.50344439 0.45555856 0.40396023\n",
            " 0.50420951 0.56827839 0.42070604 0.50596883 0.47386334 0.42766962\n",
            " 0.47495628 0.51451671 0.48800862 0.53559137 0.44730653 0.41650405\n",
            " 0.48193469 0.43402148 0.49892511 0.47352527 0.42543423 0.45747655\n",
            " 0.454783   0.46433386 0.5021958  0.43909873 0.4808666  0.48663675\n",
            " 0.51169555 0.50010565 0.53936599 0.38298784 0.44283587 0.44051863\n",
            " 0.4448879  0.43833564 0.50004955 0.49188777 0.4916097  0.52661407\n",
            " 0.39293051 0.50365207 0.56207111 0.51308895 0.46311319 0.40039913\n",
            " 0.40969492 0.4098335  0.51618512 0.48238889 0.45953454 0.44073283\n",
            " 0.4121186  0.43904346 0.47845574 0.45063887 0.44322938 0.47977844\n",
            " 0.47327651 0.50335487 0.4460509  0.45522226]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VivPfQPvp0M7",
        "outputId": "3966ec5e-0df1-4bdb-b556-92e522bd8a6c"
      },
      "source": [
        "slr.predict(X)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEGGOTuDp4iG",
        "outputId": "34580167-876c-4b23-d7b5-13b7241d9eef"
      },
      "source": [
        "slr.predict_proba(X)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.43833564, 0.48490489, 0.44051863, 0.4448879 , 0.4401868 ,\n",
              "       0.47352527, 0.50596883, 0.4749527 , 0.42766962, 0.50983544,\n",
              "       0.42917444, 0.50004955, 0.38298784, 0.46433386, 0.50010565,\n",
              "       0.45063887, 0.51451671, 0.43909873, 0.40396023, 0.44283587,\n",
              "       0.53559137, 0.45555856, 0.42070604, 0.43904346, 0.44322938,\n",
              "       0.44730653, 0.4121186 , 0.45789966, 0.4808666 , 0.44308799,\n",
              "       0.44073283, 0.43402148, 0.45747655, 0.46271433, 0.52661407,\n",
              "       0.53598208, 0.45494755, 0.39293051, 0.50335487, 0.46358098,\n",
              "       0.46003267, 0.47495628, 0.4469123 , 0.45953454, 0.47386334,\n",
              "       0.48800862, 0.48663675, 0.45522226, 0.4840057 , 0.47845574,\n",
              "       0.56207111, 0.49892511, 0.454783  , 0.47327651, 0.50030383,\n",
              "       0.41650405, 0.52588673, 0.40517258, 0.4098335 , 0.53484782,\n",
              "       0.51169555, 0.4601833 , 0.47779332, 0.49542053, 0.54846854,\n",
              "       0.53936599, 0.47182457, 0.49188777, 0.3863694 , 0.40969492,\n",
              "       0.50420951, 0.53095541, 0.38368202, 0.46311319, 0.50964572,\n",
              "       0.44231405, 0.47977844, 0.50344439, 0.48193469, 0.41053931,\n",
              "       0.40039913, 0.46741351, 0.48998205, 0.4460509 , 0.42543423,\n",
              "       0.43235786, 0.56827839, 0.48728331, 0.5107375 , 0.48238889,\n",
              "       0.51618512, 0.5021958 , 0.49892511, 0.50779725, 0.54176495,\n",
              "       0.50365207, 0.45116733, 0.4916097 , 0.56874573, 0.51308895])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZJc0SV1p-jj",
        "outputId": "02e911ba-c59e-453d-ad31-acb065250284"
      },
      "source": [
        "slr.predict_proba(X_test)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.46003267, 0.53598208, 0.46741351, 0.4601833 , 0.56874573,\n",
              "       0.3863694 , 0.43235786, 0.45789966, 0.46358098, 0.4469123 ,\n",
              "       0.46271433, 0.53484782, 0.49542053, 0.54176495, 0.52588673,\n",
              "       0.48728331, 0.45116733, 0.48490489, 0.53095541, 0.48998205,\n",
              "       0.50983544, 0.49892511, 0.44308799, 0.5107375 , 0.44231405,\n",
              "       0.50964572, 0.47779332, 0.47182457, 0.41053931, 0.4840057 ])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfLb8Hj_qEZM"
      },
      "source": [
        "y_pred = slr.predict(X_test)\n",
        "y_pred = y_pred.reshape(y_test.shape)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E78Nay9aq7ka",
        "outputId": "9f02f903-293b-4eef-9dfb-666caaf15544"
      },
      "source": [
        "print('正解率:{}'.format(accuracy_score(y_test, y_pred)))\n",
        "print('適合率:{}'.format(precision_score(y_test, y_pred)))\n",
        "print('再現率:{}'.format(recall_score(y_test, y_pred)))\n",
        "print('F値:{}'.format(f1_score(y_test, y_pred)))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正解率:0.5\n",
            "適合率:0.7777777777777778\n",
            "再現率:0.35\n",
            "F値:0.48275862068965514\n",
            "[[ 8  2]\n",
            " [13  7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miyImExKz4Qh",
        "outputId": "f354a6eb-8448-4e04-ee98-e3bfdfcb5b1d"
      },
      "source": [
        "# scikit-learnによる実装と比べ、正しく動いているかを確認\n",
        "# 必要なライブラリの読み込み\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# ロジスティック回帰モデルのインスタンスを作成\n",
        "lr = LogisticRegression()\n",
        "# ロジスティック回帰モデルの重みを学習\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred2 = lr.predict(X_test)\n",
        "y_pred2 = y_pred2.reshape(y_test.shape)\n",
        "\n",
        "print('scikit-learnの場合の正解率:{}'.format(accuracy_score(y_test, y_pred2)))\n",
        "print('scikit-learnの場合の適合率:{}'.format(precision_score(y_test, y_pred2)))\n",
        "print('scikit-learnの場合の再現率:{}'.format(recall_score(y_test, y_pred2)))\n",
        "print('scikit-learnの場合のF値:{}'.format(f1_score(y_test, y_pred2)))\n",
        "print(confusion_matrix(y_test, y_pred2))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learnの場合の正解率:0.8666666666666667\n",
            "scikit-learnの場合の適合率:0.9\n",
            "scikit-learnの場合の再現率:0.9\n",
            "scikit-learnの場合のF値:0.9\n",
            "[[ 8  2]\n",
            " [ 2 18]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V42TDvMO2JyY"
      },
      "source": [
        "〈問題５解答〉\n",
        "以上のとおり、スクラッチ実装した結果は、scikit-learnによる実装と比べ、正しく動いていることを確認できた。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZcssryGy26w"
      },
      "source": [
        "【問題6】学習曲線のプロット\n",
        "\n",
        "学習曲線を見て損失が適切に下がっているかどうか確認してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EkqFiLIh2Bf"
      },
      "source": [
        "# 問題6のヒント\n",
        "# クラス内に描画関数を追加してもよいですし、インスタンス変数として損失値を保持しているので、クラス外部で描画してもよいです。"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-Elvekf3MJr"
      },
      "source": [
        "# 必要なライブラリのインポート\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Awj5Helq673r",
        "outputId": "ea0ebf75-a647-4aff-d00e-d2bc1deee824"
      },
      "source": [
        "plt.plot(np.arange(1, len(slr.loss) + 1), slr.loss, label = 'train_loss', linewidth = 10)\n",
        "plt.plot(np.arange(1, len(slr.val_loss) + 1), slr.val_loss, label = 'val_loss', linewidth = 10)\n",
        "plt.legend()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1a967ff850>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlrUIIwTA4lu"
      },
      "source": [
        "〈問題6解答〉\n",
        "以上のとおり、学習曲線を見ると損失が適切に下がっていることを確認できた。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w00lZRKpzDzQ"
      },
      "source": [
        "【問題7】決定領域の可視化\n",
        "\n",
        "決定領域を可視化してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8upsBgCiCCc"
      },
      "source": [
        "# 問題7のヒント\n",
        "# 「決定領域を可視化する」とは、分類結果を分かりやすく色分けすることを言います。\n",
        "# 点の描画は問題ないかと思いますが、背景色の決定境界線の描画に関しては、使用している説明変数の範囲にある全ての値の候補に対する推定結果を描画します。\n",
        "# ヒントとしては、numpyのmeshgridという関数を使用し、**説明変数の範囲にある全ての値の候補** を求め、predictするイメージです。\n",
        "# クラス内に描画関数を追加してもよいですし、インスタンス変数として損失値を保持しているので、クラス外部で描画してもよいです。"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8LCMtum3OBi"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "def decision_region(X, y, model, step = 0.01, title = 'decision region', xlabel = 'xlabel', ylabel = 'ylabel', target_names = ['setosa', 'versicolor']):\n",
        "  scatter_color = ['red', 'blue']\n",
        "  contourf_color = ['pink', 'skyblue']\n",
        "  n_class = 2\n",
        "  marker = ['o', '^']\n",
        "\n",
        "  # numpyのmeshgridという関数を使用し、**説明変数の範囲にある全ての値の候補** を求め、predictする\n",
        "  mesh_f0, mesh_f1 = np.meshgrid(np.arange(np.min(X[:, 0])-0.5, np.max(X[:, 0])+0.5, step), np.arange(np.min(X[:, 1])-0.5, np.max(X[:, 1]) + 0.5, step))\n",
        "  mesh = np.c_[np.ravel(mesh_f0), np.ravel(mesh_f1)]\n",
        "  y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
        "\n",
        "  # 描画\n",
        "  plt.title(title)\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap = ListedColormap(contourf_color))\n",
        "  plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors = 'y', linewidths = 3, alpha = 0.5)\n",
        "  for i, j in enumerate(set(y)):\n",
        "    plt.scatter(X[y == j][:, 0], X[y == j][:, 1], s = 80, color = scatter_color[i], label = target_names[i], marker = marker[i])\n",
        "  patches = [mpatches.Patch(color = scatter_color[i], label = target_names[i]) for i in range(n_class)]\n",
        "  plt.legend(handles = patches)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q0niIBjVRQX"
      },
      "source": [
        "X = iris.data[:100, :]\n",
        "y = iris.target[:100]\n",
        "X = X[:, [0, 2]]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 0)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzBfeLZ2V3NP",
        "outputId": "c8cf7c1c-4462-4c67-f533-3a90efe1d77f"
      },
      "source": [
        "slr = ScratchLogisticRegression(num_iter = 10000, lr = 1, bias = True, verbose = True)\n",
        "slr.fit(X = X_train, y = y_train, X_val = X_test, y_val = y_test)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99964738 0.99595982 0.00657047 0.01121292 0.00620311 0.99961117\n",
            " 0.01801889 0.00299628 0.02301086 0.99984261 0.00841795 0.00841795\n",
            " 0.9995969  0.95855246 0.97137607 0.9994919  0.00944176 0.99964097\n",
            " 0.00188748 0.99684957 0.009999   0.01907258 0.00695944 0.99867073\n",
            " 0.85259723 0.99491215 0.01941272 0.99856602 0.9998888  0.9999082\n",
            " 0.01608012 0.00737126 0.9888708  0.01518919 0.009999   0.99883705\n",
            " 0.99952903 0.00780726 0.99781186 0.9998653  0.99907727 0.00342388\n",
            " 0.009999   0.99995991 0.01121292 0.99848067 0.99754385 0.98211474\n",
            " 0.00875745 0.05206479]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "p6qqC7uvWY-6",
        "outputId": "e32a0fd2-c3de-4457-d72a-4b8422709d62"
      },
      "source": [
        "decision_region(X, y, slr, step = 0.01, title = 'Scratch Logistic Regression', xlabel = 'xlabel', ylabel = 'ylabel', target_names = ['setosa', 'versicolor'])"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1yPjieszMRj"
      },
      "source": [
        "【問題8】（アドバンス課題）重みの保存\n",
        "\n",
        "検証が容易になるように、学習した重みを保存および読み込みができるようにしましょう。pickleモジュールやNumPyのnp.savezを利用します。"
      ]
    }
  ]
}