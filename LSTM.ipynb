{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNekhXQO3vSWe5j5HCymgKP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinmiura/diveintocode-ml/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D4FjDkfv5On"
      },
      "source": [
        "**Sprintの目的**\n",
        "\n",
        "・発展的なRNNの手法を理解する\n",
        "\n",
        "・ドキュメントを網羅的に読む\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1tSULoqwAWj"
      },
      "source": [
        "**どのように学ぶか**\n",
        "\n",
        "Kerasに用意されているRNN関係のレイヤーを動作させながら学んでいきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QnP9LBIwKvT"
      },
      "source": [
        "# 2.KerasのRecurrentレイヤー\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcyhHJqPwO9p"
      },
      "source": [
        "Kerasには複数のRecurrentレイヤーや、それに関連したクラスが用意されています。今回のSprintではこれらすべてを動かした上で、それぞれの役割を説明できる状態を目指します。\n",
        "\n",
        "\n",
        "以下のドキュメントにまとめられています。\n",
        "\n",
        "\n",
        "Recurrentレイヤー - Keras Documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZOPwy40wT14"
      },
      "source": [
        "**【問題1】各種手法の実行**\n",
        "\n",
        "Kerasには4種類のReccurentレイヤーが用意されています。SimpleRNN以外はゲート付きリカレントニューラルネットワークです。\n",
        "\n",
        "\n",
        "SimpleRNN\n",
        "GRU\n",
        "LSTM\n",
        "ConvLSTM2D\n",
        "\n",
        "これらを実行してください。この中でSimpleRNN、GRU、LSTMは同様のタスクに用いることができるため、精度の比較も行なってください。\n",
        "\n",
        "\n",
        "Keras公式のサンプルコードを利用してください。\n",
        "\n",
        "\n",
        "LSTMのサンプルコード\n",
        "\n",
        "\n",
        "keras-apache-mxnet/imdb_lstm.py at master · awslabs/keras-apache-mxnet\n",
        "\n",
        "\n",
        "ConvLSTM2Dのサンプルコード\n",
        "\n",
        "\n",
        "keras-apache-mxnet/conv_lstm.py at master · awslabs/keras-apache-mxnet\n",
        "\n",
        "\n",
        "このサンプルコードをそのまま使う必要はなく、ノード数やエポックなどは変更して構いません。すべて実行する上での実行時間を考慮した数に設定してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9bmBLSyRbZ_"
      },
      "source": [
        "# ライブラリのimport \n",
        "from __future__ import print_function\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "from keras.layers.recurrent import SimpleRNN"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfFdO3lYR7R9",
        "outputId": "49c0c6eb-4cf7-4ed2-a0df-8aff9ad9f577"
      },
      "source": [
        "# imdbデータの読み込みと整形\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# 確認\n",
        "x_train.shape, y_train.shape,x_test.shape, y_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 80), (25000,), (25000, 80), (25000,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHfC1e5dR_tP",
        "outputId": "38a4f29c-92b1-4720-84bc-a16a7c7eff19"
      },
      "source": [
        "# モデルの定義\n",
        "# Embeddingに関して：https://kento1109.hatenablog.com/entry/2017/12/02/114515\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,593,025\n",
            "Trainable params: 2,593,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggSNrBCrSCQb",
        "outputId": "7a17515a-1c03-4f12-9231-9f788c503e38"
      },
      "source": [
        "# コンパイルと学習\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=1,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 148s 185ms/step - loss: 0.6814 - accuracy: 0.5517 - val_loss: 0.6414 - val_accuracy: 0.6104\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc4235d8950>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1yK-yV2SDHp",
        "outputId": "973325e0-dfc2-40c5-fae2-91c5c60c72a5"
      },
      "source": [
        "# 評価\n",
        "score, acc = model.evaluate(\n",
        "    x_test, \n",
        "    y_test,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 9s 11ms/step - loss: 0.6414 - accuracy: 0.6104\n",
            "Test score: 0.6413683295249939\n",
            "Test accuracy: 0.6104400157928467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQsGda63TWfU"
      },
      "source": [
        "# SimpleRNNの場合\n",
        "# ライブラリのimport\n",
        "from keras.layers.recurrent import SimpleRNN\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZHk44UqTbvy",
        "outputId": "de95fc72-9322-4450-bd7a-8c8dd8323c66"
      },
      "source": [
        "# imdbデータの読み込みと整形\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# 確認\n",
        "x_train.shape, y_train.shape,x_test.shape, y_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 80), (25000,), (25000, 80), (25000,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2K7SZ5nTeAC",
        "outputId": "302ae232-a494-40da-e4ec-6b82debce59f"
      },
      "source": [
        "# モデルの定義\n",
        "# Embeddingに関して：https://kento1109.hatenablog.com/entry/2017/12/02/114515\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoaZIebRTgQz",
        "outputId": "05f6f9fe-aa5b-435e-9d88-dabcfa3d2806"
      },
      "source": [
        "# コンパイルと学習\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=1,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 403s 512ms/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.3523 - val_accuracy: 0.8444\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc38ef35110>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0akrXUvUzvA",
        "outputId": "3a38c496-9a67-4dd4-9295-48f2d69f40b0"
      },
      "source": [
        "# 評価\n",
        "score, acc = model.evaluate(\n",
        "    x_test, \n",
        "    y_test,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 24s 31ms/step - loss: 0.3523 - accuracy: 0.8444\n",
            "Test score: 0.352308988571167\n",
            "Test accuracy: 0.8444399833679199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAyPtF-KU1kN"
      },
      "source": [
        "# GRUの場合\n",
        "# ライブラリのimport\n",
        "from keras.layers.recurrent import GRU\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "669ul3RqU6HK",
        "outputId": "42b5baf1-1996-4f98-a764-fcb555abca81"
      },
      "source": [
        "# imdbデータの読み込みと整形\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# 確認\n",
        "x_train.shape, y_train.shape,x_test.shape, y_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 80), (25000,), (25000, 80), (25000,))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rKbPVW2U_yl",
        "outputId": "ac4aac3c-a758-483c-8c93-7af766845459"
      },
      "source": [
        "# モデルの定義\n",
        "# Embeddingに関して：https://kento1109.hatenablog.com/entry/2017/12/02/114515\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 128)               98688     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,658,817\n",
            "Trainable params: 2,658,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0j55qKOVAhI",
        "outputId": "7d5b4ede-5dcb-4f0b-8fc1-a878fe5d4ccb"
      },
      "source": [
        "# コンパイルと学習\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=1,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 438s 556ms/step - loss: 0.4569 - accuracy: 0.7725 - val_loss: 0.3767 - val_accuracy: 0.8378\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc41eda5610>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvYDjBI6VDYC",
        "outputId": "3716a777-7a8d-46f6-d2d4-5c2befdd32e7"
      },
      "source": [
        "# 評価\n",
        "score, acc = model.evaluate(\n",
        "    x_test, \n",
        "    y_test,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 24s 31ms/step - loss: 0.3767 - accuracy: 0.8378\n",
            "Test score: 0.3766569495201111\n",
            "Test accuracy: 0.8378000259399414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "UR4CF8O1VIFG",
        "outputId": "6aceb232-109a-4ab5-9b79-8612c1b9361b"
      },
      "source": [
        "# ConvLSTM2D\n",
        "# ライブラリのimport\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from keras import backend as K\n",
        "%matplotlib notebook\n",
        "if K.backend() == 'mxnet':\n",
        "    raise NotImplementedError(\"MXNet Backend: ConvLSTM2D Layer is not supported yet.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-35120a554ebf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional_recurrent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvLSTM2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'BatchNormalization' from 'keras.layers.normalization' (/usr/local/lib/python3.7/dist-packages/keras/layers/normalization/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5cHUeUdVWKk"
      },
      "source": [
        "# データ作成\n",
        "def generate_movies(n_samples=1200, n_frames=15):\n",
        "    \"\"\"テスト動画作成関数（理解不要）\n",
        "    Parameters\n",
        "    -----------\n",
        "    n_samples : 動画数 \n",
        "    n_frames : フレーム数\n",
        "    \"\"\"\n",
        "    row = 80\n",
        "    col = 80\n",
        "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
        "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
        "                              dtype=np.float)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # Add 3 to 7 moving squares\n",
        "        n = np.random.randint(3, 8)\n",
        "\n",
        "        for j in range(n):\n",
        "            # Initial position\n",
        "            xstart = np.random.randint(20, 60)\n",
        "            ystart = np.random.randint(20, 60)\n",
        "            # Direction of motion\n",
        "            directionx = np.random.randint(0, 3) - 1\n",
        "            directiony = np.random.randint(0, 3) - 1\n",
        "\n",
        "            # Size of the square\n",
        "            w = np.random.randint(2, 4)\n",
        "\n",
        "            for t in range(n_frames):\n",
        "                x_shift = xstart + directionx * t\n",
        "                y_shift = ystart + directiony * t\n",
        "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
        "                             y_shift - w: y_shift + w, 0] += 1\n",
        "\n",
        "                # Make it more robust by adding noise.\n",
        "                # The idea is that if during inference,\n",
        "                # the value of the pixel is not exactly one,\n",
        "                # we need to train the network to be robust and still\n",
        "                # consider it as a pixel belonging to a square.\n",
        "                if np.random.randint(0, 2):\n",
        "                    noise_f = (-1)**np.random.randint(0, 2)\n",
        "                    noisy_movies[i, t,\n",
        "                                 x_shift - w - 1: x_shift + w + 1,\n",
        "                                 y_shift - w - 1: y_shift + w + 1,\n",
        "                                 0] += noise_f * 0.1\n",
        "\n",
        "                # Shift the ground truth by 1\n",
        "                x_shift = xstart + directionx * (t + 1)\n",
        "                y_shift = ystart + directiony * (t + 1)\n",
        "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
        "                               y_shift - w: y_shift + w, 0] += 1\n",
        "\n",
        "    # Cut to a 40x40 window\n",
        "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
        "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
        "    noisy_movies[noisy_movies >= 1] = 1\n",
        "    shifted_movies[shifted_movies >= 1] = 1\n",
        "    return noisy_movies, shifted_movies\n",
        "\n",
        "# 上記関数実行\n",
        "noisy_movies, shifted_movies = generate_movies(n_samples=1200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7i1EEswVZ6-"
      },
      "source": [
        "# どのようなデータが生成されているか出力\n",
        "# データ選択\n",
        "index = 1\n",
        "x= noisy_movies[index]\n",
        "\n",
        "# 描画\n",
        "fig= plt.figure()\n",
        "viewer= fig.add_subplot(111)\n",
        "plt.ion()\n",
        "fig.show()\n",
        "for i in range(len(x)):\n",
        "    viewer.clear()\n",
        "    viewer.imshow(x[i])\n",
        "    plt.pause(.1)\n",
        "    fig.canvas.draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeLppTZDVoW0"
      },
      "source": [
        "# モデルの定義とコンパイル\n",
        "seq = Sequential()\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   input_shape=(None, 40, 40, 1),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
        "               activation='sigmoid',\n",
        "               padding='same', data_format='channels_last'))\n",
        "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
        "\n",
        "seq.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CBraj4uVr_s"
      },
      "source": [
        "# 学習\n",
        "seq.fit(\n",
        "    noisy_movies[:100], \n",
        "    shifted_movies[:100], \n",
        "    batch_size=10,\n",
        "    epochs=1, \n",
        "    validation_split=0.05\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q3spSpzVs0J"
      },
      "source": [
        "# テスト用データ取得\n",
        "which = 1004\n",
        "track = noisy_movies[which][:7, ::, ::, ::] # 7フレームまで取得\n",
        "track2 = noisy_movies[which][::, ::, ::, ::] # 正解データ\n",
        "\n",
        "# 予測\n",
        "for j in range(16):\n",
        "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "    new = new_pos[::, -1, ::, ::, ::]\n",
        "    track = np.concatenate((track, new), axis=0)\n",
        "\n",
        "# 描画\n",
        "track2 = noisy_movies[which][::, ::, ::, ::]\n",
        "for i in range(15):\n",
        "    # 初期化\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "    \n",
        "    ## 予測値描画\n",
        "    ax = fig.add_subplot(121)\n",
        "    # テキスト\n",
        "    if i >= 7:\n",
        "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
        "    else:\n",
        "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
        "    # 描画\n",
        "    toplot = track[i, ::, ::, 0]\n",
        "    plt.imshow(toplot)\n",
        "    \n",
        "    ## 実測値描画\n",
        "    ax = fig.add_subplot(122)\n",
        "    # テキスト\n",
        "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
        "    # 描画\n",
        "    toplot = track2[i, ::, ::, 0]\n",
        "    if i >= 2:\n",
        "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
        "    plt.imshow(toplot)\n",
        "    \n",
        "    ## 保存\n",
        "    plt.savefig('%i_animate.png' % (i + 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1moNQcmwmsT"
      },
      "source": [
        "**【問題2】（アドバンス課題）複数のデータセット間での比較**\n",
        "\n",
        "他のデータセットでも実験を行なってください。\n",
        "\n",
        "\n",
        "データセット - Keras Documentation\n",
        "\n",
        "\n",
        "Kerasで簡単に利用できる自然言語データセットとしてロイターのニュースワイヤー トピックス分類があります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Ph1PcgwwJK"
      },
      "source": [
        "【問題3】他のクラスの説明\n",
        "\n",
        "ドキュメントには他にも関連するクラスが記載されています。それらがどういうものなのかを説明してください。この中には実際に扱うことは少ないクラスも含まれています。\n",
        "\n",
        "\n",
        "・RNN⇨ノード間の接続が時間的な順序に沿った有向グラフを形成する人工ニューラルネットワークのクラスのこと。フィードフォワード・ネットワークが有する時系列データの性質（パターン）を十分に学習することができないという問題を解決できるものである。\n",
        "\n",
        "・SimpleRNNCell⇨SimpleRNNのCellクラスです。セルは、再帰的に現れる同じネットワーク構造。\n",
        "\n",
        "・GRUCell⇨LSTMを簡略化したゲートを持つ再帰的なユニットであるgru layerのセルクラス。GRUは、LSTMとGRUはLSTMのゲートを使用するというコンセプトはそのままながら、パラメータを削減し、計算時間を短縮できる。\n",
        "\n",
        "・LSTMCell⇨基本的にはLSTM層用のCellクラスで、1ステップ分の計算ロジックを含む。RNNの学習で大きな問題となる勾配消失問題に対して当該問題を起こさない（もしくは起こしにくい）ようにできるもの。\n",
        "\n",
        "・StackedRNNCells⇨RNNセルスタックの動作を単一セルのように見せるためのラッパー。\n",
        "\n",
        "・CuDNNGRU⇨CuDNNを使った高速GRUの実装。\n",
        "\n",
        "・CuDNNLSTM⇨CuDNNを用いた高速なLSTM実装。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P10ThOipvn1W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}